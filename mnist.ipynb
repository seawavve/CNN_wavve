{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "efficientWorkin.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyNiA8simy26Qi1t+D1qONiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/seawavve/CNN_wavve/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Uc-jGXjQSLso",
        "outputId": "1638874a-0f1d-4b04-f045-a463661a6f90"
      },
      "source": [
        "\n",
        "# import warnings\n",
        "# warnings.simplefilter(action='ignore', category=FutureWarning)\n",
        "\n",
        "import numpy as np \n",
        "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
        "from matplotlib import pyplot\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras import datasets\n",
        "import numpy as np\n",
        "import sys\n",
        "\n",
        "print('Python version : ', sys.version)\n",
        "print('Keras version : ', keras.__version__)\n",
        "\n",
        "img_rows = 28   \n",
        "img_cols = 28\n",
        "(x_train, y_train), (x_test, y_test) =keras.datasets.mnist.load_data()  \n",
        "\n",
        "input_shape = (img_rows, img_cols,1)\n",
        "x_train = x_train.reshape(x_train.shape[0], img_rows, img_cols, 1)  \n",
        "x_test = x_test.reshape(x_test.shape[0], img_rows, img_cols, 1)\n",
        "\n",
        "x_train = x_train.astype('float32') / 255.\n",
        "x_test = x_test.astype('float32') / 255.\n",
        "\n",
        "print('x_train shape:', x_train.shape)\n",
        "print(x_train.shape[0], 'train samples')\n",
        "print(x_test.shape[0], 'test samples')\n",
        "\n",
        "from keras.utils import np_utils\n",
        "y_train = np_utils.to_categorical(y_train)\n",
        "y_test = np_utils.to_categorical(y_test)\n",
        "num_classes = y_test.shape[1]\n",
        "\n",
        "epochs = 10\n",
        "filename='checkpoint.h5'.format(epochs)\n",
        "early_stopping=EarlyStopping(monitor='val_loss',mode='min',patience=15,verbose=1)          \n",
        "checkpoint=ModelCheckpoint(filename,monitor='val_loss',verbose=1,save_best_only=True,mode='auto')   \n",
        "\n",
        "inputs = keras.Input(shape = input_shape, name = 'input')\n",
        "output = layers.Conv2D(filters = 32, kernel_size = [3,3], padding = 'same', activation='relu')(inputs)\n",
        "output = layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding = 'same')(output)\n",
        "k = layers.Dropout(rate=0.2)(output)\n",
        "output= layers.Conv2D(filters=32, kernel_size=[3,3], padding='same', activation='relu')(output)\n",
        "# output=layers.Add()([k,output])\n",
        "\n",
        "output = layers.GlobalAveragePooling2D()(output)\n",
        "output = layers.Dense(1000, activation ='relu', name='fc0')(output)\n",
        "dropout = layers.Dropout(rate=0.2)(output)\n",
        "output = layers.Dense(10, activation = 'softmax', name='output')(dropout)\n",
        "\n",
        "model = keras.Model(inputs = inputs, outputs = output)\n",
        "model.summary()\n",
        "\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "history = model.fit(x_train, y_train, epochs=epochs, verbose=1, validation_data=(x_test, y_test),callbacks=[checkpoint,early_stopping]) #학습\n",
        "\n",
        "score = model.evaluate(x_test, y_test, verbose=0)\n",
        "print('Test loss:',  score[0])\n",
        "print('Test accuracy:', score[1])"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Python version :  3.7.12 (default, Sep 10 2021, 00:21:48) \n",
            "[GCC 7.5.0]\n",
            "Keras version :  2.7.0\n",
            "x_train shape: (60000, 28, 28, 1)\n",
            "60000 train samples\n",
            "10000 test samples\n",
            "Model: \"model_6\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input (InputLayer)          [(None, 28, 28, 1)]       0         \n",
            "                                                                 \n",
            " conv2d_9 (Conv2D)           (None, 28, 28, 32)        320       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 14, 14, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_10 (Conv2D)          (None, 14, 14, 32)        9248      \n",
            "                                                                 \n",
            " global_average_pooling2d_3   (None, 32)               0         \n",
            " (GlobalAveragePooling2D)                                        \n",
            "                                                                 \n",
            " fc0 (Dense)                 (None, 1000)              33000     \n",
            "                                                                 \n",
            " dropout_7 (Dropout)         (None, 1000)              0         \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                10010     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 52,578\n",
            "Trainable params: 52,578\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1867/1875 [============================>.] - ETA: 0s - loss: 1.2168 - accuracy: 0.5568\n",
            "Epoch 00001: val_loss improved from inf to 0.62585, saving model to checkpoint.h5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 1.2142 - accuracy: 0.5579 - val_loss: 0.6258 - val_accuracy: 0.8069\n",
            "Epoch 2/10\n",
            "1861/1875 [============================>.] - ETA: 0s - loss: 0.5057 - accuracy: 0.8416\n",
            "Epoch 00002: val_loss improved from 0.62585 to 0.34854, saving model to checkpoint.h5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.5049 - accuracy: 0.8418 - val_loss: 0.3485 - val_accuracy: 0.8910\n",
            "Epoch 3/10\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.3373 - accuracy: 0.8951\n",
            "Epoch 00003: val_loss improved from 0.34854 to 0.25230, saving model to checkpoint.h5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.3375 - accuracy: 0.8950 - val_loss: 0.2523 - val_accuracy: 0.9223\n",
            "Epoch 4/10\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.2627 - accuracy: 0.9185\n",
            "Epoch 00004: val_loss improved from 0.25230 to 0.21810, saving model to checkpoint.h5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.2628 - accuracy: 0.9185 - val_loss: 0.2181 - val_accuracy: 0.9335\n",
            "Epoch 5/10\n",
            "1872/1875 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9342\n",
            "Epoch 00005: val_loss improved from 0.21810 to 0.16818, saving model to checkpoint.h5\n",
            "1875/1875 [==============================] - 7s 3ms/step - loss: 0.2145 - accuracy: 0.9341 - val_loss: 0.1682 - val_accuracy: 0.9472\n",
            "Epoch 6/10\n",
            "1868/1875 [============================>.] - ETA: 0s - loss: 0.1855 - accuracy: 0.9433\n",
            "Epoch 00006: val_loss improved from 0.16818 to 0.14801, saving model to checkpoint.h5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1853 - accuracy: 0.9434 - val_loss: 0.1480 - val_accuracy: 0.9548\n",
            "Epoch 7/10\n",
            "1870/1875 [============================>.] - ETA: 0s - loss: 0.1669 - accuracy: 0.9485\n",
            "Epoch 00007: val_loss improved from 0.14801 to 0.14241, saving model to checkpoint.h5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1669 - accuracy: 0.9485 - val_loss: 0.1424 - val_accuracy: 0.9563\n",
            "Epoch 8/10\n",
            "1864/1875 [============================>.] - ETA: 0s - loss: 0.1497 - accuracy: 0.9539\n",
            "Epoch 00008: val_loss improved from 0.14241 to 0.12808, saving model to checkpoint.h5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1498 - accuracy: 0.9539 - val_loss: 0.1281 - val_accuracy: 0.9607\n",
            "Epoch 9/10\n",
            "1874/1875 [============================>.] - ETA: 0s - loss: 0.1365 - accuracy: 0.9586\n",
            "Epoch 00009: val_loss improved from 0.12808 to 0.12420, saving model to checkpoint.h5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1366 - accuracy: 0.9585 - val_loss: 0.1242 - val_accuracy: 0.9605\n",
            "Epoch 10/10\n",
            "1871/1875 [============================>.] - ETA: 0s - loss: 0.1233 - accuracy: 0.9618\n",
            "Epoch 00010: val_loss improved from 0.12420 to 0.09370, saving model to checkpoint.h5\n",
            "1875/1875 [==============================] - 7s 4ms/step - loss: 0.1232 - accuracy: 0.9618 - val_loss: 0.0937 - val_accuracy: 0.9719\n",
            "Test loss: 0.09369906783103943\n",
            "Test accuracy: 0.9718999862670898\n"
          ]
        }
      ]
    }
  ]
}